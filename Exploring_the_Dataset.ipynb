{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM79HetCdmnm7POmSIZMwFl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mayar215999/data-science-project/blob/main/Exploring_the_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install micropip\n",
        "!pip install piplite\n",
        "\n",
        "# Install micropip if it's not already available.\n",
        "try:\n",
        "    import micropip\n",
        "except ImportError:\n",
        "    import importlib\n",
        "    # For Google Colab or environments where importlib.util.find_spec is available\n",
        "    if importlib.util.find_spec(\"google.colab\"):\n",
        "        import google.colab\n",
        "        google.colab.output.enable_custom_widget_manager()\n",
        "    # Use piplite if in a browser environment like JupyterLite or Pyodide.\n",
        "    import piplite\n",
        "    await piplite.install(\"micropip\")\n",
        "    import micropip\n",
        "\n",
        "# Now you can use micropip to install pandas.\n",
        "await micropip.install('pandas')\n",
        "\n",
        "# Import pandas after installation\n",
        "import pandas as pd\n",
        "print(pd.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFcfOjcxK1VB",
        "outputId": "a915028d-3775-4a25-d934-7fe75ff83eda"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting micropip\n",
            "  Downloading micropip-0.7.2-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.11/dist-packages (from micropip) (24.2)\n",
            "Downloading micropip-0.7.2-py3-none-any.whl (46 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/46.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: micropip\n",
            "Successfully installed micropip-0.7.2\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement piplite (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for piplite\u001b[0m\u001b[31m\n",
            "\u001b[0m2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "\n",
        "import requests\n",
        "\n",
        "def download(url, filename):\n",
        "    \"\"\"Downloads a file from a URL and saves it to a local file.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the file to download.\n",
        "        filename (str): The name of the file to save the downloaded data to.\n",
        "    \"\"\"\n",
        "    response = requests.get(url, stream=True)\n",
        "    response.raise_for_status()  # Raise an exception for bad status codes\n",
        "    with open(filename, \"wb\") as f:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            f.write(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyDg176BLO7i",
        "outputId": "f4946f8d-7384-4477-fc30-fdf9cf66af63"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def download(url, filename):\n",
        "    \"\"\"Downloads a file from a URL and saves it to a local file.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the file to download.\n",
        "        filename (str): The name of the file to save the downloaded data to.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()  # Raise an exception for bad status codes\n",
        "        with open(filename, \"wb\") as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "    except requests.exceptions.HTTPError as err:\n",
        "        print(f\"HTTP Error: {err}\")\n",
        "        # You can add further error handling or logging here, like printing the status code.\n",
        "        print(f\"Status code: {response.status_code}\")\n",
        "        # This will give you the 404, 500, etc. code\n",
        "    except Exception as err:\n",
        "        print(f\"An unexpected error occurred: {err}\")"
      ],
      "metadata": {
        "id": "GlWRnxhoLTyO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\""
      ],
      "metadata": {
        "id": "a8uGCRRlLbIH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def download(url, filename):\n",
        "    \"\"\"Downloads a file from a URL and saves it to a local file.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the file to download.\n",
        "        filename (str): The name of the file to save the downloaded data to.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()  # Raise an exception for bad status codes\n",
        "        with open(filename, \"wb\") as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "    except requests.exceptions.HTTPError as err:\n",
        "        print(f\"HTTP Error: {err}\")\n",
        "        # You can add further error handling or logging here, like printing the status code.\n",
        "        print(f\"Status code: {response.status_code}\")\n",
        "        # This will give you the 404, 500, etc. code\n",
        "    except Exception as err:\n",
        "        print(f\"An unexpected error occurred: {err}\")\n",
        "\n",
        "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"  # Correct URL\n",
        "\n",
        "download(file_path, \"survey_data.csv\")  # Download and save as \"survey_data.csv\"\n",
        "\n",
        "# Now you can load the downloaded data using pandas\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"survey_data.csv\")\n",
        "print(df.head())  # Display the first few rows to verify the data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhZYLMkqMCWV",
        "outputId": "f76b15a8-4acf-43de-9735-46120039bed0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ResponseId                      MainBranch                 Age  \\\n",
            "0           1  I am a developer by profession  Under 18 years old   \n",
            "1           2  I am a developer by profession     35-44 years old   \n",
            "2           3  I am a developer by profession     45-54 years old   \n",
            "3           4           I am learning to code     18-24 years old   \n",
            "4           5  I am a developer by profession     18-24 years old   \n",
            "\n",
            "            Employment RemoteWork   Check  \\\n",
            "0  Employed, full-time     Remote  Apples   \n",
            "1  Employed, full-time     Remote  Apples   \n",
            "2  Employed, full-time     Remote  Apples   \n",
            "3   Student, full-time        NaN  Apples   \n",
            "4   Student, full-time        NaN  Apples   \n",
            "\n",
            "                                    CodingActivities  \\\n",
            "0                                              Hobby   \n",
            "1  Hobby;Contribute to open-source projects;Other...   \n",
            "2  Hobby;Contribute to open-source projects;Other...   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "\n",
            "                                             EdLevel  \\\n",
            "0                          Primary/elementary school   \n",
            "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
            "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
            "3  Some college/university study without earning ...   \n",
            "4  Secondary school (e.g. American high school, G...   \n",
            "\n",
            "                                           LearnCode  \\\n",
            "0                             Books / Physical media   \n",
            "1  Books / Physical media;Colleague;On the job tr...   \n",
            "2  Books / Physical media;Colleague;On the job tr...   \n",
            "3  Other online resources (e.g., videos, blogs, f...   \n",
            "4  Other online resources (e.g., videos, blogs, f...   \n",
            "\n",
            "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
            "0                                                NaN  ...            NaN   \n",
            "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
            "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
            "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
            "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
            "\n",
            "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
            "0            NaN            NaN            NaN             NaN   \n",
            "1            0.0            0.0            0.0             0.0   \n",
            "2            NaN            NaN            NaN             NaN   \n",
            "3            NaN            NaN            NaN             NaN   \n",
            "4            NaN            NaN            NaN             NaN   \n",
            "\n",
            "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
            "0             NaN                    NaN        NaN                 NaN    NaN  \n",
            "1             0.0                    NaN        NaN                 NaN    NaN  \n",
            "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
            "3             NaN               Too long       Easy                 NaN    NaN  \n",
            "4             NaN              Too short       Easy                 NaN    NaN  \n",
            "\n",
            "[5 rows x 114 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def download(url, filename):\n",
        "    \"\"\"Downloads a file from a URL and saves it to a local file.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the file to download.\n",
        "        filename (str): The name of the file to save the downloaded data to.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()  # Raise an exception for bad status codes\n",
        "        with open(filename, \"wb\") as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "    except requests.exceptions.HTTPError as err:\n",
        "        print(f\"HTTP Error: {err}\")\n",
        "        # You can add further error handling or logging here, like printing the status code.\n",
        "        print(f\"Status code: {response.status_code}\")\n",
        "        # This will give you the 404, 500, etc. code\n",
        "    except Exception as err:\n",
        "        print(f\"An unexpected error occurred: {err}\")\n",
        "\n",
        "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"  # Correct URL\n",
        "\n",
        "download(file_path, \"survey_data.csv\")  # Download and save as \"survey_data.csv\"\n",
        "\n",
        "# Now you can load the downloaded data using pandas\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"survey_data.csv\") # Changed file_name to survey_data.csv\n",
        "print(df.head())  # Display the first few rows to verify the data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEj59dvVMVK4",
        "outputId": "64e2a1da-55ae-4eda-9cea-5872a755b1b7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ResponseId                      MainBranch                 Age  \\\n",
            "0           1  I am a developer by profession  Under 18 years old   \n",
            "1           2  I am a developer by profession     35-44 years old   \n",
            "2           3  I am a developer by profession     45-54 years old   \n",
            "3           4           I am learning to code     18-24 years old   \n",
            "4           5  I am a developer by profession     18-24 years old   \n",
            "\n",
            "            Employment RemoteWork   Check  \\\n",
            "0  Employed, full-time     Remote  Apples   \n",
            "1  Employed, full-time     Remote  Apples   \n",
            "2  Employed, full-time     Remote  Apples   \n",
            "3   Student, full-time        NaN  Apples   \n",
            "4   Student, full-time        NaN  Apples   \n",
            "\n",
            "                                    CodingActivities  \\\n",
            "0                                              Hobby   \n",
            "1  Hobby;Contribute to open-source projects;Other...   \n",
            "2  Hobby;Contribute to open-source projects;Other...   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "\n",
            "                                             EdLevel  \\\n",
            "0                          Primary/elementary school   \n",
            "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
            "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
            "3  Some college/university study without earning ...   \n",
            "4  Secondary school (e.g. American high school, G...   \n",
            "\n",
            "                                           LearnCode  \\\n",
            "0                             Books / Physical media   \n",
            "1  Books / Physical media;Colleague;On the job tr...   \n",
            "2  Books / Physical media;Colleague;On the job tr...   \n",
            "3  Other online resources (e.g., videos, blogs, f...   \n",
            "4  Other online resources (e.g., videos, blogs, f...   \n",
            "\n",
            "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
            "0                                                NaN  ...            NaN   \n",
            "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
            "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
            "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
            "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
            "\n",
            "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
            "0            NaN            NaN            NaN             NaN   \n",
            "1            0.0            0.0            0.0             0.0   \n",
            "2            NaN            NaN            NaN             NaN   \n",
            "3            NaN            NaN            NaN             NaN   \n",
            "4            NaN            NaN            NaN             NaN   \n",
            "\n",
            "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
            "0             NaN                    NaN        NaN                 NaN    NaN  \n",
            "1             0.0                    NaN        NaN                 NaN    NaN  \n",
            "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
            "3             NaN               Too long       Easy                 NaN    NaN  \n",
            "4             NaN              Too short       Easy                 NaN    NaN  \n",
            "\n",
            "[5 rows x 114 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def download(url, filename):\n",
        "    \"\"\"Downloads a file from a URL and saves it to a local file.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the file to download.\n",
        "        filename (str): The name of the file to save the downloaded data to.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()  # Raise an exception for bad status codes\n",
        "        with open(filename, \"wb\") as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "    except requests.exceptions.HTTPError as err:\n",
        "        print(f\"HTTP Error: {err}\")\n",
        "        # You can add further error handling or logging here, like printing the status code.\n",
        "        print(f\"Status code: {response.status_code}\")\n",
        "        # This will give you the 404, 500, etc. code\n",
        "    except Exception as err:\n",
        "        print(f\"An unexpected error occurred: {err}\")\n",
        "\n",
        "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"  # Correct URL\n",
        "\n",
        "download(file_path, \"survey_data.csv\")  # Download and save as \"survey_data.csv\"\n",
        "\n",
        "# Now you can load the downloaded data using pandas\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"survey_data.csv\")  # Changed file_name to survey_data.csv\n",
        "print(df.iloc[:5, :5])  # Display the first 5 rows and first 5 columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emiDkX0eMmfJ",
        "outputId": "14118e31-10dd-4fc4-a994-f0f7d1f47a72"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ResponseId                      MainBranch                 Age  \\\n",
            "0           1  I am a developer by profession  Under 18 years old   \n",
            "1           2  I am a developer by profession     35-44 years old   \n",
            "2           3  I am a developer by profession     45-54 years old   \n",
            "3           4           I am learning to code     18-24 years old   \n",
            "4           5  I am a developer by profession     18-24 years old   \n",
            "\n",
            "            Employment RemoteWork  \n",
            "0  Employed, full-time     Remote  \n",
            "1  Employed, full-time     Remote  \n",
            "2  Employed, full-time     Remote  \n",
            "3   Student, full-time        NaN  \n",
            "4   Student, full-time        NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def download(url, filename):\n",
        "    \"\"\"Downloads a file from a URL and saves it to a local file.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the file to download.\n",
        "        filename (str): The name of the file to save the downloaded data to.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()  # Raise an exception for bad status codes\n",
        "        with open(filename, \"wb\") as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "    except requests.exceptions.HTTPError as err:\n",
        "        print(f\"HTTP Error: {err}\")\n",
        "        # You can add further error handling or logging here, like printing the status code.\n",
        "        print(f\"Status code: {response.status_code}\")\n",
        "        # This will give you the 404, 500, etc. code\n",
        "    except Exception as err:\n",
        "        print(f\"An unexpected error occurred: {err}\")\n",
        "\n",
        "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"  # Correct URL\n",
        "\n",
        "download(file_path, \"survey_data.csv\")  # Download and save as \"survey_data.csv\"\n",
        "\n",
        "# Now you can load the downloaded data using pandas\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"survey_data.csv\")  # Changed file_name to survey_data.csv\n",
        "\n",
        "# Print the number of rows\n",
        "num_rows = df.shape[0]  # Get the number of rows using the shape attribute\n",
        "print(f\"The dataset has {num_rows} rows.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu9ZHI5ZM6oq",
        "outputId": "2408e7fe-17e0-4576-9189-2f86ccd8ae87"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset has 65437 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def download(url, filename):\n",
        "    \"\"\"Downloads a file from a URL and saves it to a local file.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the file to download.\n",
        "        filename (str): The name of the file to save the downloaded data to.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()  # Raise an exception for bad status codes\n",
        "        with open(filename, \"wb\") as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "    except requests.exceptions.HTTPError as err:\n",
        "        print(f\"HTTP Error: {err}\")\n",
        "        # You can add further error handling or logging here, like printing the status code.\n",
        "        print(f\"Status code: {response.status_code}\")\n",
        "        # This will give you the 404, 500, etc. code\n",
        "    except Exception as err:\n",
        "        print(f\"An unexpected error occurred: {err}\")\n",
        "\n",
        "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"  # Correct URL\n",
        "\n",
        "download(file_path, \"survey_data.csv\")  # Download and save as \"survey_data.csv\"\n",
        "\n",
        "# Now you can load the downloaded data using pandas\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"survey_data.csv\")  # Changed file_name to survey_data.csv\n",
        "\n",
        "# Print the number of rows\n",
        "num_rows = df.shape[0]  # Get the number of rows using the shape attribute\n",
        "print(f\"The dataset has {num_rows} rows.\")\n",
        "\n",
        "# Print the number of columns\n",
        "num_cols = df.shape[1]  # Get the number of columns using the shape attribute\n",
        "print(f\"The dataset has {num_cols} columns.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQn9iJIiNTan",
        "outputId": "8bc5e7b7-a615-4711-f7d2-8fbb0f2ccea3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset has 65437 rows.\n",
            "The dataset has 114 columns.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def download(url, filename):\n",
        "    \"\"\"Downloads a file from a URL and saves it to a local file.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the file to download.\n",
        "        filename (str): The name of the file to save the downloaded data to.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()  # Raise an exception for bad status codes\n",
        "        with open(filename, \"wb\") as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "    except requests.exceptions.HTTPError as err:\n",
        "        print(f\"HTTP Error: {err}\")\n",
        "        # You can add further error handling or logging here, like printing the status code.\n",
        "        print(f\"Status code: {response.status_code}\")\n",
        "        # This will give you the 404, 500, etc. code\n",
        "    except Exception as err:\n",
        "        print(f\"An unexpected error occurred: {err}\")\n",
        "\n",
        "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"  # Correct URL\n",
        "\n",
        "download(file_path, \"survey_data.csv\")  # Download and save as \"survey_data.csv\"\n",
        "\n",
        "# Now you can load the downloaded data using pandas\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"survey_data.csv\")  # Changed file_name to survey_data.csv\n",
        "\n",
        "# Print the number of rows\n",
        "num_rows = df.shape[0]  # Get the number of rows using the shape attribute\n",
        "print(f\"The dataset has {num_rows} rows.\")\n",
        "\n",
        "# Print the number of columns\n",
        "num_cols = df.shape[1]  # Get the number of columns using the shape attribute\n",
        "print(f\"The dataset has {num_cols} columns.\")\n",
        "\n",
        "# --- Changes to handle the 'Age' column ---\n",
        "\n",
        "# 1. Convert 'Age' column to numeric, handling errors\n",
        "# If 'coerce', then invalid parsing will be set as NaN\n",
        "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
        "\n",
        "# 2. Calculate and print the mean age, ignoring NaN values\n",
        "mean_age = df['Age'].mean(skipna=True)\n",
        "print(f\"The mean age of the survey participants is: {mean_age}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9ibXSJoOGQL",
        "outputId": "6908ed2f-696e-443f-afcb-686efa6d15ae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset has 65437 rows.\n",
            "The dataset has 114 columns.\n",
            "The mean age of the survey participants is: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def download(url, filename):\n",
        "    \"\"\"Downloads a file from a URL and saves it to a local file.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the file to download.\n",
        "        filename (str): The name of the file to save the downloaded data to.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()  # Raise an exception for bad status codes\n",
        "        with open(filename, \"wb\") as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "    except requests.exceptions.HTTPError as err:\n",
        "        print(f\"HTTP Error: {err}\")\n",
        "        # You can add further error handling or logging here, like printing the status code.\n",
        "        print(f\"Status code: {response.status_code}\")\n",
        "        # This will give you the 404, 500, etc. code\n",
        "    except Exception as err:\n",
        "        print(f\"An unexpected error occurred: {err}\")\n",
        "\n",
        "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"  # Correct URL\n",
        "\n",
        "download(file_path, \"survey_data.csv\")  # Download and save as \"survey_data.csv\"\n",
        "\n",
        "# Now you can load the downloaded data using pandas\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"survey_data.csv\")  # Changed file_name to survey_data.csv\n",
        "\n",
        "# Print the number of rows\n",
        "num_rows = df.shape[0]  # Get the number of rows using the shape attribute\n",
        "print(f\"The dataset has {num_rows} rows.\")\n",
        "\n",
        "# Print the number of columns\n",
        "num_cols = df.shape[1]  # Get the number of columns using the shape attribute\n",
        "print(f\"The dataset has {num_cols} columns.\")\n",
        "\n",
        "# --- Changes to handle the 'Age' column ---\n",
        "\n",
        "# 1. Convert 'Age' column to numeric, handling errors\n",
        "# If 'coerce', then invalid parsing will be set as NaN\n",
        "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
        "\n",
        "# 2. Calculate and print the mean age, ignoring NaN values\n",
        "mean_age = df['Age'].mean(skipna=True)\n",
        "print(f\"The mean age of the survey participants is: {mean_age}\")\n",
        "\n",
        "# --- Print datatypes of all columns ---\n",
        "print(\"\\nDatatypes of all columns:\")\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFrvuAFab4N5",
        "outputId": "760c2c26-ca15-4167-a853-238411b95b7c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset has 65437 rows.\n",
            "The dataset has 114 columns.\n",
            "The mean age of the survey participants is: nan\n",
            "\n",
            "Datatypes of all columns:\n",
            "ResponseId               int64\n",
            "MainBranch              object\n",
            "Age                    float64\n",
            "Employment              object\n",
            "RemoteWork              object\n",
            "                        ...   \n",
            "JobSatPoints_11        float64\n",
            "SurveyLength            object\n",
            "SurveyEase              object\n",
            "ConvertedCompYearly    float64\n",
            "JobSat                 float64\n",
            "Length: 114, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def download(url, filename):\n",
        "    \"\"\"Downloads a file from a URL and saves it to a local file.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the file to download.\n",
        "        filename (str): The name of the file to save the downloaded data to.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()  # Raise an exception for bad status codes\n",
        "        with open(filename, \"wb\") as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "    except requests.exceptions.HTTPError as err:\n",
        "        print(f\"HTTP Error: {err}\")\n",
        "        # You can add further error handling or logging here, like printing the status code.\n",
        "        print(f\"Status code: {response.status_code}\")\n",
        "        # This will give you the 404, 500, etc. code\n",
        "    except Exception as err:\n",
        "        print(f\"An unexpected error occurred: {err}\")\n",
        "\n",
        "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"  # Correct URL\n",
        "\n",
        "download(file_path, \"survey_data.csv\")  # Download and save as \"survey_data.csv\"\n",
        "\n",
        "# Now you can load the downloaded data using pandas\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"survey_data.csv\")  # Changed file_name to survey_data.csv\n",
        "\n",
        "# Print the number of rows\n",
        "num_rows = df.shape[0]  # Get the number of rows using the shape attribute\n",
        "print(f\"The dataset has {num_rows} rows.\")\n",
        "\n",
        "# Print the number of columns\n",
        "num_cols = df.shape[1]  # Get the number of columns using the shape attribute\n",
        "print(f\"The dataset has {num_cols} columns.\")\n",
        "\n",
        "# --- Changes to handle the 'Age' column ---\n",
        "\n",
        "# 1. Convert 'Age' column to numeric, handling errors\n",
        "# If 'coerce', then invalid parsing will be set as NaN\n",
        "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
        "\n",
        "# 2. Calculate and print the mean age, ignoring NaN values\n",
        "mean_age = df['Age'].mean(skipna=True)\n",
        "print(f\"The mean age of the survey participants is: {mean_age}\")\n",
        "\n",
        "# --- Print datatypes of all columns ---\n",
        "print(\"\\nDatatypes of all columns:\")\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWnt07YZcA0A",
        "outputId": "a14314db-e831-478d-e831-dd865bbaedc9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset has 65437 rows.\n",
            "The dataset has 114 columns.\n",
            "The mean age of the survey participants is: nan\n",
            "\n",
            "Datatypes of all columns:\n",
            "ResponseId               int64\n",
            "MainBranch              object\n",
            "Age                    float64\n",
            "Employment              object\n",
            "RemoteWork              object\n",
            "                        ...   \n",
            "JobSatPoints_11        float64\n",
            "SurveyLength            object\n",
            "SurveyEase              object\n",
            "ConvertedCompYearly    float64\n",
            "JobSat                 float64\n",
            "Length: 114, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def download(url, filename):\n",
        "    \"\"\"Downloads a file from a URL and saves it to a local file.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the file to download.\n",
        "        filename (str): The name of the file to save the downloaded data to.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()  # Raise an exception for bad status codes\n",
        "        with open(filename, \"wb\") as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "    except requests.exceptions.HTTPError as err:\n",
        "        print(f\"HTTP Error: {err}\")\n",
        "        # You can add further error handling or logging here, like printing the status code.\n",
        "        print(f\"Status code: {response.status_code}\")\n",
        "        # This will give you the 404, 500, etc. code\n",
        "    except Exception as err:\n",
        "        print(f\"An unexpected error occurred: {err}\")\n",
        "\n",
        "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"  # Correct URL\n",
        "\n",
        "download(file_path, \"survey_data.csv\")  # Download and save as \"survey_data.csv\"\n",
        "\n",
        "# Now you can load the downloaded data using pandas\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"survey_data.csv\")  # Changed file_name to survey_data.csv\n",
        "\n",
        "# Print the number of rows\n",
        "num_rows = df.shape[0]  # Get the number of rows using the shape attribute\n",
        "print(f\"The dataset has {num_rows} rows.\")\n",
        "\n",
        "# Print the number of columns\n",
        "num_cols = df.shape[1]  # Get the number of columns using the shape attribute\n",
        "print(f\"The dataset has {num_cols} columns.\")\n",
        "\n",
        "# --- Changes to handle the 'Age' column ---\n",
        "\n",
        "# 1. Convert 'Age' column to numeric, handling errors\n",
        "# If 'coerce', then invalid parsing will be set as NaN\n",
        "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
        "\n",
        "# 2. Calculate and print the mean age, ignoring NaN values\n",
        "mean_age = df['Age'].mean(skipna=True)\n",
        "print(f\"The mean age of the survey participants is: {mean_age}\")\n",
        "\n",
        "# --- Print datatypes of all columns ---\n",
        "print(\"\\nDatatypes of all columns:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# --- Print the number of unique countries ---\n",
        "num_unique_countries = df['Country'].nunique()\n",
        "print(f\"\\nThe dataset contains data from {num_unique_countries} unique countries.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jqWA_QIccLt",
        "outputId": "dfc29a4d-3092-411b-f8b8-24db9fb70ea4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset has 65437 rows.\n",
            "The dataset has 114 columns.\n",
            "The mean age of the survey participants is: nan\n",
            "\n",
            "Datatypes of all columns:\n",
            "ResponseId               int64\n",
            "MainBranch              object\n",
            "Age                    float64\n",
            "Employment              object\n",
            "RemoteWork              object\n",
            "                        ...   \n",
            "JobSatPoints_11        float64\n",
            "SurveyLength            object\n",
            "SurveyEase              object\n",
            "ConvertedCompYearly    float64\n",
            "JobSat                 float64\n",
            "Length: 114, dtype: object\n",
            "\n",
            "The dataset contains data from 185 unique countries.\n"
          ]
        }
      ]
    }
  ]
}