{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOC/10U5XVrrzw+GB2sYDRF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mayar215999/data-science-project/blob/main/beautiful_soup_web_scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sSrwp10dHg26"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup # this module helps in web scrapping.\n",
        "import requests  # this module helps us to download a webpage"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"http://www.ibm.com\""
      ],
      "metadata": {
        "id": "xj1Df6rOHqgY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the contents of the webpage in text format and store in a variable called data\n",
        "data  = requests.get(url).text"
      ],
      "metadata": {
        "id": "FfD_foxHHvKz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(data,\"html.parser\")  # create a soup object using the variable 'data'"
      ],
      "metadata": {
        "id": "YKbC4QpKHzyS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for link in soup.find_all('a'):  # in html anchor/link is represented by the tag <a>\n",
        "    print(link.get('href'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bC4X4EmnH1jD",
        "outputId": "45c040c9-1f80-43e6-9078-a63471225a10"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.ibm.com/granite?lnk=hpad1us\n",
            "https://developer.ibm.com/technologies/artificial-intelligence?lnk=hpad2us\n",
            "https://www.ibm.com/products/watsonx-code-assistant?lnk=hpad3us\n",
            "https://www.ibm.com/watsonx/developer/?lnk=hpad4us\n",
            "https://www.ibm.com/thought-leadership/institute-business-value/report/ceo-generative-ai?lnk=hpab1us\n",
            "https://www.ibm.com/think/reports/ai-in-action?lnk=hpab2us\n",
            "https://www.ibm.com/impact/ai-ethics?lnk=hpab3us\n",
            "https://www.ibm.com/account/reg/signup?formid=news-urx-52954&lnk=hpab4us\n",
            "https://www.ibm.com/artificial-intelligence?lnk=hpfp1us\n",
            "https://www.ibm.com/hybrid-cloud?lnk=hpfp2us\n",
            "https://www.ibm.com/consulting?lnk=hpfp3us\n",
            "https://www.ibm.com/case-studies/water-corporation\n",
            "https://www.ibm.com/case-studies/ibm-software-team\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for link in soup.find_all('img'):# in html image is represented by the tag <img>\n",
        "    print(link.get('src'))"
      ],
      "metadata": {
        "id": "fBVdQPMLH4jw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The below URL contains a html table with data about colors and color codes.\n",
        "URL = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/HTMLColorCodes.html\""
      ],
      "metadata": {
        "id": "T3FzqZh5IE2y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the contents of the webpage in text format and store in a variable called data\n",
        "data  = requests.get(URL).text"
      ],
      "metadata": {
        "id": "QwTidtSpIJIq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(data,\"html.parser\")"
      ],
      "metadata": {
        "id": "LMQmkYMbINzp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#find a html table in the web page\n",
        "table = soup.find('table') # in html table is represented by the tag <table>"
      ],
      "metadata": {
        "id": "iAqbq-3WIRnu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for row in table.find_all('tr'): # in html table row is represented by the tag <tr>\n",
        "    # Get all columns in each row.\n",
        "    cols = row.find_all('td') # in html a column is represented by the tag <td>\n",
        "    color_name = cols[2].getText() # store the value in column 3 as color_name\n",
        "    color_code = cols[3].getText() # store the value in column 4 as color_code\n",
        "    print(\"{}--->{}\".format(color_name,color_code))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pndXhvMtIVCU",
        "outputId": "475f1591-0e9d-4131-a3ed-8b065a18ab98"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Color Name--->Hex Code#RRGGBB\n",
            "lightsalmon--->#FFA07A\n",
            "salmon--->#FA8072\n",
            "darksalmon--->#E9967A\n",
            "lightcoral--->#F08080\n",
            "coral--->#FF7F50\n",
            "tomato--->#FF6347\n",
            "orangered--->#FF4500\n",
            "gold--->#FFD700\n",
            "orange--->#FFA500\n",
            "darkorange--->#FF8C00\n",
            "lightyellow--->#FFFFE0\n",
            "lemonchiffon--->#FFFACD\n",
            "papayawhip--->#FFEFD5\n",
            "moccasin--->#FFE4B5\n",
            "peachpuff--->#FFDAB9\n",
            "palegoldenrod--->#EEE8AA\n",
            "khaki--->#F0E68C\n",
            "darkkhaki--->#BDB76B\n",
            "yellow--->#FFFF00\n",
            "lawngreen--->#7CFC00\n",
            "chartreuse--->#7FFF00\n",
            "limegreen--->#32CD32\n",
            "lime--->#00FF00\n",
            "forestgreen--->#228B22\n",
            "green--->#008000\n",
            "powderblue--->#B0E0E6\n",
            "lightblue--->#ADD8E6\n",
            "lightskyblue--->#87CEFA\n",
            "skyblue--->#87CEEB\n",
            "deepskyblue--->#00BFFF\n",
            "lightsteelblue--->#B0C4DE\n",
            "dodgerblue--->#1E90FF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this url contains the data you need to scrape\n",
        "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\""
      ],
      "metadata": {
        "id": "NfgXZBtFIr9u"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "VR6fEHlaI1yb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\"\n",
        "response = requests.get(url)\n",
        "html_content = response.content"
      ],
      "metadata": {
        "id": "uQggnGY7I5pM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(html_content, 'html.parser')"
      ],
      "metadata": {
        "id": "IH7cxRxEI8vm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\"\n",
        "\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    with open(\"programming_languages.html\", \"w\") as file:\n",
        "        file.write(response.text)\n",
        "    print(\"Webpage downloaded successfully!\")\n",
        "else:\n",
        "    print(f\"Failed to download webpage. Status code: {response.status_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V79nWF8JF-t",
        "outputId": "5c32320d-5a81-40fa-c2e6-284f63be7929"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Webpage downloaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "with open(\"programming_languages.html\", \"r\") as file:\n",
        "    html_content = file.read()\n",
        "\n",
        "soup = BeautifulSoup(html_content, \"html.parser\")"
      ],
      "metadata": {
        "id": "tpA_qE7bJUSU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "language_names = []\n",
        "annual_salaries = []\n",
        "\n",
        "table = soup.find('table')  # Find the table containing the data\n",
        "\n",
        "for row in table.find_all('tr'):  # Iterate through each row in the table\n",
        "    cols = row.find_all('td')  # Get all columns in the row\n",
        "    if len(cols) >= 2:  # Check if there are at least 2 columns (language and salary)\n",
        "        language_names.append(cols[0].text.strip())  # Extract language name\n",
        "        annual_salaries.append(cols[1].text.strip())  # Extract annual salary"
      ],
      "metadata": {
        "id": "iUznuCOHJZMQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you have language_names and annual_salaries lists from previous steps\n",
        "\n",
        "data = {'Language': language_names, 'Average Annual Salary': annual_salaries}\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv('popular-languages.csv', index=False)"
      ],
      "metadata": {
        "id": "VinYfG9AJjgL"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}